
====
CRF - 20.05.2020
====

Summary results: 
Worst fold

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<creator>            97.46        90           71.68        79.8         113    
<software>           88.74        86.14        70.76        77.7         448    
<url>                98.82        54.55        57.14        55.81        21     
<version>            97.59        81.54        87.6         84.46        121    

all (micro avg.)     95.66        84.59        73.4         78.6         703    
all (macro avg.)     95.66        78.06        71.8         74.44        703    

===== Instance-level results =====

Total expected instances:   238
Correct instances:          114
Instance-level recall:      47.9

Best fold:

===== Field-level results =====

label                accuracy     precision    recall       f1           support

<creator>            97.07        81           76.42        78.64        106    
<software>           90.62        88.1         75.85        81.52        410    
<url>                99.53        85.71        70.59        77.42        17     
<version>            98.01        93.53        86.09        89.66        151    

all (micro avg.)     96.31        88.12        78.07        82.79        684    
all (macro avg.)     96.31        87.09        77.24        81.81        684    

===== Instance-level results =====

Total expected instances:   231
Correct instances:          128
Instance-level recall:      55.41


Average over 10 folds: 

label                accuracy     precision    recall       f1           support

<creator>            97.26        85.93        75.5         80.3         1119   
<software>           89.47        86.51        72.96        79.11        4131   
<url>                99.23        66.64        62.98        63.75        172    
<version>            97.9         89.88        84.99        87.25        1273   

all                  95.97        86.57        75.38        80.55  

===== Instance-level results =====

Total expected instances:   231.7
Correct instances:          126.7
Instance-level recall:      54.68




====
CRF - 28-05-2020
====

Average over 10 folds:

label                accuracy     precision    recall       f1           support

<creator>            97.3         86.77        75.26        80.59        1119
<software>           89.53        86.34        73.4         79.33        4131
<url>                99.26        69.27        59.86        63.58        172
<version>            97.85        90.2         83.8         86.83        1273

all                  95.98        86.8         75.34        80.66

===== Instance-level results =====

Total expected instances:   231.9
Correct instances:          130
Instance-level recall:      56.06


N-Fold evaluation for software model is realized in 58660917 ms


====
CRF - 30-05-2020
====

Average over 10 folds: 

label                accuracy     precision    recall       f1           support

<creator>            97.32        86.74        75.31        80.6         1119   
<software>           89.65        86.18        74.07        79.64        4131   
<url>                99.24        68.58        59.66        63.15        172    
<version>            97.95        90.53        84.74        87.47        1273   

all                  96.04        86.73        75.91        80.95  

===== Instance-level results =====

Total expected instances:   231.9
Correct instances:          131
Instance-level recall:      56.49


N-Fold evaluation for software model is realized in 60075829 ms

BUILD SUCCESSFUL in 16h 41m 19s



===
BidLSTM CRF + features - 30-05-2020
===

** Worst ** model scores - run 8
                  precision    recall  f1-score   support

       <creator>     0.7864    0.7714    0.7788       105
      <software>     0.8005    0.6939    0.7434       428
           <url>     0.2609    0.4000    0.3158        15
       <version>     0.8849    0.8786    0.8817       140

all (micro avg.)     0.7972    0.7369    0.7659       688


** Best ** model scores - run 7
                  precision    recall  f1-score   support

       <creator>     0.8704    0.8952    0.8826       105
      <software>     0.8272    0.7827    0.8043       428
           <url>     0.6000    0.6000    0.6000        15
       <version>     0.8836    0.9214    0.9021       140

all (micro avg.)     0.8412    0.8241    0.8326       688

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

       <creator>     0.8259    0.8524    0.8387       105
      <software>     0.8057    0.7570    0.7802       428
           <url>     0.3615    0.4067    0.3805        15
       <version>     0.8999    0.9114    0.9055       140

all (micro avg.)     0.8171    0.7953    0.8059       



===
BidLSTM CRF + ELMo + features - 31-05-2020
===

Evaluation:


** Worst ** model scores - run 3
                  precision    recall  f1-score   support

       <creator>     0.8019    0.9043    0.8500        94
      <software>     0.8112    0.8832    0.8456       428
           <url>     0.4118    0.6364    0.5000        22
       <version>     0.8613    0.8806    0.8708       134

all (micro avg.)     0.8008    0.8776    0.8374       678


** Best ** model scores - run 6
                  precision    recall  f1-score   support

       <creator>     0.8447    0.9255    0.8832        94
      <software>     0.8588    0.8528    0.8558       428
           <url>     0.6071    0.7727    0.6800        22
       <version>     0.8915    0.8582    0.8745       134

all (micro avg.)     0.8526    0.8614    0.8569       678

----------------------------------------------------------------------

Average over 10 folds
                  precision    recall  f1-score   support

       <creator>     0.8304    0.9096    0.8680        94
      <software>     0.8441    0.8535    0.8480       428
           <url>     0.5931    0.6864    0.6321        22
       <version>     0.8687    0.8664    0.8674       134

all (micro avg.)     0.8368    0.8584    0.8470    


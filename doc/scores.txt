First version Aug. 2018 (CRF)

Labeling took: 1781 ms

===== Token-level results =====


label                accuracy     precision    recall       f1     

<creator>            99.61        58.8         60.35        59.57  
<software>           99.38        77.67        51.39        61.86  
<url>                99.95        66.67        93.62        77.88  
<version-date>       99.99        100          22.22        36.36  
<version-number>     99.67        85.53        69.52        76.7   

all fields           99.72        74.73        60.77        67.03   (micro average)
                     99.72        77.73        59.42        62.47   (macro average)

===== Field-level results =====

label                accuracy     precision    recall       f1     

<creator>            94.52        61.64        52.33        56.6   
<software>           82.7         73.43        48.25        58.24  
<url>                99.76        60           75           66.67  
<version-date>       99.44        100          22.22        36.36  
<version-number>     94.44        71.74        60           65.35  

all fields           94.17        70.71        51.15        59.36   (micro average)
                     94.17        73.36        51.56        56.64   (macro average)

===== Instance-level results =====

Total expected instances:   212
Correct instances:          58
Instance-level recall:      27.36

Split, training and evaluation for software model is realized in 25636259 ms



Version Aug. 24th 2018 (CRF)

===== Token-level results =====

label                precision    recall       f1     

<creator>            58.8         60.35        59.57  
<software>           77.67        51.39        61.86  
<url>                66.67        93.62        77.88  
<version-date>       100          22.22        36.36  
<version-number>     85.53        69.52        76.7   

all fields           74.73        60.77        67.03   (micro average)

===== Field-level results =====

label                precision    recall       f1     

<creator>            61.64        52.33        56.6   
<software>           73.43        48.25        58.24  
<url>                60           75           66.67  
<version-date>       100          22.22        36.36  
<version-number>     71.74        60           65.35  

all fields           70.71        51.15        59.36   (micro average)



Version Oct. 19th 2018 (CRF)

Labeling took: 1821 ms

===== Token-level results =====


label                precision    recall       f1     

<creator>            71.72        71           71.36  
<software>           82.48        50.37        62.54  
<url>                40           66.67        50     
<version-date>       100          6.25         11.76  
<version-number>     87.14        81.77        84.37  

all fields           79.68        64.37        71.21   (micro average)

===== Field-level results =====

label                precision    recall       f1     

<creator>            70.65        59.09        64.36  
<software>           76.61        50.61        60.95  
<url>                25           50           33.33  
<version-date>       100          6.25         11.76  
<version-number>     72.82        69.44        71.09  

all fields           73.92        54.59        62.8    (micro average)

===== Instance-level results =====

Total expected instances:   236
Correct instances:          80
Instance-level recall:      33.9





Version May 2nd 2019 (CRF)

Labeling took: 1458 ms


===== Token-level results =====


label                accuracy     precision    recall       f1     

<creator>            99.6         77.37        65.73        71.08  
<software>           99.43        83.23        62.47        71.37  
<url>                99.87        77.91        67.68        72.43  
<version-date>       99.98        66.67        44.44        53.33  
<version-number>     99.74        85.46        89.1         87.24  

all fields           99.72        82.18        71.83        76.66   (micro average)
                     99.72        78.13        65.88        71.09   (macro average)

===== Field-level results =====

label                accuracy     precision    recall       f1     

<creator>            94.84        77.5         62           68.89  
<software>           85.36        71.64        58.54        64.43  
<url>                99.63        85.71        66.67        75     
<version-date>       99.36        66.67        44.44        53.33  
<version-number>     97.15        82.65        85.26        83.94  

all fields           95.27        75.77        64.71        69.8    (micro average)
                     95.27        76.84        63.38        69.12   (macro average)

===== Instance-level results =====

Total expected instances:   183
Correct instances:          68
Instance-level recall:      37.16

Split, training and evaluation for software model is realized in 11844491 ms






Version July 15th 2019 (CRF)

Labeling took: 2024 ms

===== Token-level results =====


label                accuracy     precision    recall       f1     

<creator>            99.72        79.32        65.73        71.89  
<software>           99.26        81.56        46.47        59.21  
<url>                99.53        38.38        35.15        36.69  
<version>            99.81        91.37        83.5         87.26  

all fields           99.58        77.28        58.62        66.67   (micro average)
                     99.58        72.66        57.71        63.76   (macro average)

===== Field-level results =====

label                accuracy     precision    recall       f1     

<creator>            96.01        80.58        65.35        72.17  
<software>           82.25        71.9         44.5         54.98  
<url>                98.63        41.18        36.84        38.89  
<version>            96.76        88.28        75.33        81.29  

all fields           93.42        76.94        54.88        64.06   (micro average)
                     93.42        70.49        55.51        61.83   (macro average)

===== Instance-level results =====

Total expected instances:   265
Correct instances:          102
Instance-level recall:      38.49

Split, training and evaluation for software model is realized in 8501912 ms






July 17th 2019 (CRF)
Training restricted to paragraph where at least one annotation is present (no negative examples)

Labeling took: 1796 ms

===== Token-level results =====


label                accuracy     precision    recall       f1     

<creator>            99.79        86.74        65.69        74.76  
<software>           99.49        80.71        66.22        72.75  
<url>                99.63        82.19        25.75        39.22  
<version>            99.74        78.55        83.68        81.03  

all fields           99.66        81.12        63.45        71.21   (micro average)
                     99.66        82.05        60.33        66.94   (macro average)

===== Field-level results =====

label                accuracy     precision    recall       f1     

<creator>            96.72        87.06        66.07        75.13  
<software>           87.77        79.44        68.55        73.59  
<url>                98.66        40           10.53        16.67  
<version>            96.26        77.87        76.61        77.24  

all fields           94.85        79.92        67.94        73.45   (micro average)
                     94.85        71.09        55.44        60.66   (macro average)

===== Instance-level results =====

Total expected instances:   244
Correct instances:          104
Instance-level recall:      42.62

Split, training and evaluation for software model is realized in 8107718 ms


BUILD SUCCESSFUL in 2h 15m 9s





July 18th 2019 - 10% XML corpus reviewed

Labeling took: 1718 ms

===== Token-level results =====


label                accuracy     precision    recall       f1     

<creator>            99.78        77.03        75.59        76.3   
<software>           99.5         82.99        66.8         74.02  
<url>                99.58        40.88        33.94        37.09  
<version>            99.85        91.99        85.99        88.89  

all fields           99.68        78.65        68.81        73.4    (micro average)
                     99.68        73.22        65.58        69.08   (macro average)

===== Field-level results =====

label                accuracy     precision    recall       f1     

<creator>            97.06        82.61        76.77        79.58  
<software>           86.79        77.37        65.23        70.78  
<url>                98.87        50           40           44.44  
<version>            97.89        88.79        85.59        87.16  

all fields           95.15        80.21        70.73        75.17   (micro average)
                     95.15        74.69        66.9         70.49   (macro average)

===== Instance-level results =====

Total expected instances:   227
Correct instances:          107
Instance-level recall:      47.14

Split, training and evaluation for software model is realized in 8298033 ms




August 6th 2019 - 75% XML corpus reviewed

Labeling took: 1687 ms

===== Token-level results =====


label                accuracy     precision    recall       f1     

<creator>            99.79        79.27        72.86        75.93  
<software>           99.48        88.86        65.04        75.1   
<url>                99.75        77.85        59.18        67.25  
<version>            99.81        86.79        83.22        84.97  

all fields           99.71        84.89        69.68        76.54   (micro average)
                     99.71        83.19        70.07        75.81   (macro average)

===== Field-level results =====

label                accuracy     precision    recall       f1     

<creator>            96.8         82.56        72.45        77.17  
<software>           87.82        84.47        65.2         73.6   
<url>                99.32        80           53.33        64     
<version>            97.18        85.71        80.36        82.95  

all fields           95.28        84.3         69.14        75.97   (micro average)
                     95.28        83.19        67.84        74.43   (macro average)

===== Instance-level results =====

Total expected instances:   203
Correct instances:          96
Instance-level recall:      47.29

Split, training and evaluation for software model is realized in 8524881 ms


Labeling took: 1526 ms

===== Token-level results =====


label                accuracy     precision    recall       f1     

<creator>            99.84        79.39        78.92        79.15  
<software>           99.5         85.19        73.36        78.83  
<url>                99.83        86.11        71.26        77.99  
<version>            99.83        91.23        84.14        87.54  

all fields           99.75        86.04        76.65        81.07   (micro average)
                     99.75        85.48        76.92        80.88   (macro average)

===== Field-level results =====

label                accuracy     precision    recall       f1     

<creator>            97.42        82.43        73.49        77.71  
<software>           88.13        83.6         70.86        76.7   
<url>                99.48        83.33        66.67        74.07  
<version>            97.64        90.11        78.1         83.67  

all fields           95.67        84.62        72.44        78.06   (micro average)
                     95.67        84.87        72.28        78.04   (macro average)

===== Instance-level results =====

Total expected instances:   199
Correct instances:          94
Instance-level recall:      47.24

Split, training and evaluation for software model is realized in 8143269 ms




August 8th 2019 - 100% XML corpus reviewed

Labeling took: 1820 ms

===== Token-level results =====


label                accuracy     precision    recall       f1     

<creator>            99.85        83.72        82.19        82.95  
<software>           99.56        85.81        72.68        78.7   
<url>                99.81        86.02        71.11        77.86  
<version>            99.87        89.22        86.96        88.07  

all fields           99.77        86.26        77.15        81.45   (micro average)
                     99.77        86.19        78.23        81.89   (macro average)

===== Field-level results =====

label                accuracy     precision    recall       f1     

<creator>            97.31        84.21        78.43        81.22  
<software>           87.58        83.81        68.75        75.54  
<url>                99.56        85.71        75           80     
<version>            98.18        88.66        86           87.31  

all fields           95.66        84.84        73.42        78.72   (micro average)
                     95.66        85.6         77.05        81.02   (macro average)

===== Instance-level results =====

Total expected instances:   217
Correct instances:          107
Instance-level recall:      49.31

Split, training and evaluation for software model is realized in 7936500 ms



Labeling took: 1679 ms

===== Token-level results =====


label                accuracy     precision    recall       f1     

<creator>            99.79        89.27        77.04        82.7   
<software>           99.36        81.25        69.6         74.98  
<url>                99.82        75.21        66.91        70.82  
<version>            99.8         88.73        87.46        88.09  

all fields           99.69        84.36        75.52        79.7    (micro average)
                     99.69        83.61        75.25        79.15   (macro average)

===== Field-level results =====

label                accuracy     precision    recall       f1     

<creator>            96.94        86.24        76.42        81.03  
<software>           87.4         80.84        67.12        73.34  
<url>                99.58        80           66.67        72.73  
<version>            97.56        85.95        85.25        85.6   

all fields           95.37        83.03        72.45        77.38   (micro average)
                     95.37        83.26        73.86        78.18   (macro average)

===== Instance-level results =====

Total expected instances:   214
Correct instances:          110
Instance-level recall:      51.4

Split, training and evaluation for software model is realized in 7967147 ms



Labeling took: 1679 ms

===== Token-level results =====


label                accuracy     precision    recall       f1     

<creator>            99.79        88.89        65.75        75.59  
<software>           99.5         86.97        66.73        75.52  
<url>                99.59        62.84        41.33        49.87  
<version>            99.92        93.86        93.22        93.54  

all fields           99.7         85.73        68.23        75.98   (micro average)
                     99.7         83.14        66.76        73.63   (macro average)

===== Field-level results =====

label                accuracy     precision    recall       f1     

<creator>            96.78        88.16        66.34        75.71  
<software>           88.26        84.78        68.44        75.73  
<url>                98.8         63.64        36.84        46.67  
<version>            98.43        92.45        88.29        90.32  

all fields           95.57        86.51        70.8         77.87   (micro average)
                     95.57        82.26        64.98        72.11   (macro average)

===== Instance-level results =====

Total expected instances:   226
Correct instances:          119
Instance-level recall:      52.65

Split, training and evaluation for software model is realized in 7310007 ms




Labeling took: 2028 ms

===== Token-level results =====


label                accuracy     precision    recall       f1     

<creator>            99.82        86.73        73.41        79.51  
<software>           99.5         85.84        72.17        78.41  
<url>                99.76        70.13        71.37        70.74  
<version>            99.79        85.02        88.94        86.94  

all fields           99.72        83.3         76.74        79.88   (micro average)
                     99.72        81.93        76.47        78.9    (macro average)

===== Field-level results =====

label                accuracy     precision    recall       f1     

<creator>            97.55        88.35        75.21        81.25  
<software>           89.08        86.62        71.91        78.58  
<url>                99.36        62.5         66.67        64.52  
<version>            97.31        84.62        85.71        85.16  

all fields           95.83        85.84        75.1         80.11   (micro average)
                     95.83        80.52        74.87        77.38   (macro average)

===== Instance-level results =====

Total expected instances:   262
Correct instances:          147
Instance-level recall:      56.11

Split, training and evaluation for software model is realized in 7586399 ms




August 26th
-----------


===== Token-level results =====


label                accuracy     precision    recall       f1     

<creator>            99.8         82.9         68.97        75.29  
<software>           99.59        91.22        76.37        83.14  
<url>                99.84        79.31        51.49        62.44  
<version>            99.81        93.73        76.64        84.33  

all fields           99.76        89.55        72.86        80.34   (micro average)
                     99.76        86.79        68.37        76.3    (macro average)

===== Field-level results =====

label                accuracy     precision    recall       f1     

<creator>            96.65        82.56        66.98        73.96  
<software>           90.48        88.74        76.18        81.98  
<url>                99.53        71.43        50           58.82  
<version>            97.32        87.62        77.31        82.14  

all fields           96           87.37        74.51        80.43   (micro average)
                     96           82.59        67.62        74.23   (macro average)

===== Instance-level results =====

Total expected instances:   239
Correct instances:          131
Instance-level recall:      54.81








-----
DeLFT (December 2018)


Glove embeddings
no max sequence length, batch size 20

average over 10 folds
    macro f1 = 0.7276417623820862
    macro precision = 0.7506176271717047
    macro recall = 0.7070381231671554 


** Worst ** model scores - 

                  precision    recall  f1-score   support

           <url>     0.3571    0.3846    0.3704        13
       <creator>     0.7867    0.5268    0.6310       112
         number>     0.7049    0.7544    0.7288       114
      <software>     0.8163    0.6557    0.7273       427
           date>     0.5000    0.1250    0.2000        16

all (micro avg.)     0.7742    0.6334    0.6968       682


** Best ** model scores - 

                  precision    recall  f1-score   support

           <url>     0.6000    0.4615    0.5217        13
       <creator>     0.7475    0.6607    0.7014       112
         number>     0.7339    0.7982    0.7647       114
      <software>     0.7540    0.7822    0.7678       427
           date>     0.3333    0.1250    0.1818        16

all (micro avg.)     0.7434    0.7434    0.7434       682


------------------------------------------------------------------------
Glove embeddings
max sequence length 500, batch size 20

average over 10 folds
    macro f1 = 0.7150252205012938
    macro precision = 0.7108188353936724
    macro recall = 0.71994342291372 


** Worst ** model scores - 

                  precision    recall  f1-score   support

           <url>     0.2105    0.2857    0.2424        14
         number>     0.7016    0.7500    0.7250       116
           date>     1.0000    0.0833    0.1538        12
      <software>     0.7810    0.6978    0.7371       460
       <creator>     0.6484    0.5619    0.6020       105

all (micro avg.)     0.7307    0.6676    0.6977       707


** Best ** model scores - 

                  precision    recall  f1-score   support

           <url>     0.4375    0.5000    0.4667        14
         number>     0.7200    0.7759    0.7469       116
           date>     1.0000    0.5000    0.6667        12
      <software>     0.7403    0.7870    0.7629       460
       <creator>     0.6556    0.5619    0.6051       105

all (micro avg.)     0.7218    0.7412    0.7313       707


------------------------------------------------------------------------
Gloves with ELMO
max sequence length 500, batch size 20

average over 10 folds
    macro f1 = 0.7194401758824197
    macro precision = 0.7448070654152057
    macro recall = 0.6961810466760963 


** Worst ** model scores - 

                  precision    recall  f1-score   support

      <software>     0.7877    0.6696    0.7239       460
           date>     0.8571    0.5000    0.6316        12
         number>     0.7455    0.7069    0.7257       116
       <creator>     0.6489    0.5810    0.6131       105
           <url>     0.5714    0.2857    0.3810        14

all (micro avg.)     0.7570    0.6521    0.7006       707


** Best ** model scores - 

                  precision    recall  f1-score   support

      <software>     0.8113    0.7196    0.7627       460
           date>     0.8750    0.5833    0.7000        12
         number>     0.7521    0.7845    0.7679       116
       <creator>     0.6531    0.6095    0.6305       105
           <url>     0.7778    0.5000    0.6087        14

all (micro avg.)     0.7764    0.7072    0.7402       707


------------------------------------------------------------------------
Gloves with ELMo
max sequence length 1000, batch size 10

average over 10 folds
    macro f1 = 0.7418730091428716
    macro precision = 0.7500589929050274
    macro recall = 0.7343891402714933 


** Worst ** model scores - 

                  precision    recall  f1-score   support

           <url>     0.5000    0.3077    0.3810        13
         number>     0.7982    0.7778    0.7879       117
      <software>     0.7649    0.7291    0.7465       406
           date>     0.7143    0.3333    0.4545        15
       <creator>     0.6364    0.6875    0.6609       112

all (micro avg.)     0.7425    0.7134    0.7277       663


** Best ** model scores - 

                  precision    recall  f1-score   support

           <url>     0.6250    0.7692    0.6897        13
         number>     0.8158    0.7949    0.8052       117
      <software>     0.7576    0.7389    0.7481       406
           date>     0.7333    0.7333    0.7333        15
       <creator>     0.7477    0.7411    0.7444       112

all (micro avg.)     0.7623    0.7496    0.7559       663


----------------------------------------------------------------------
Gloves with ELMo
max sequence length 1500, batch size 5

average over 10 folds
    macro f1 = 0.7449552853142123
    macro precision = 0.7357331404266955
    macro recall = 0.7545454545454544 


** Worst ** model scores - 

                  precision    recall  f1-score   support

      <software>     0.7401    0.7869    0.7628       427
           <url>     0.5385    0.5385    0.5385        13
           date>     0.4545    0.3125    0.3704        16
       <creator>     0.7826    0.6429    0.7059       112
         number>     0.7016    0.7632    0.7311       114

all (micro avg.)     0.7305    0.7434    0.7369       682


** Best ** model scores - 

                  precision    recall  f1-score   support

      <software>     0.7744    0.7799    0.7771       427
           <url>     0.4375    0.5385    0.4828        13
           date>     0.5455    0.3750    0.4444        16
       <creator>     0.7864    0.7232    0.7535       112
         number>     0.7031    0.7895    0.7438       114

all (micro avg.)     0.7515    0.7581    0.7547       682


----------------------------------------------------------------------
Gloves with ELMo
max sequence length 3000, batch size 2

average over 10 folds
    macro f1 = 0.7493199184338478
    macro precision = 0.731595754812579
    macro recall = 0.7681818181818181 


** Worst ** model scores - 

                  precision    recall  f1-score   support
      <software>     0.7381    0.7986    0.7672       427

           <url>     0.4348    0.7692    0.5556        13
           date>     0.3636    0.2500    0.2963        16
       <creator>     0.7374    0.6518    0.6919       112
         number>     0.6794    0.7807    0.7265       114

all (micro avg.)     0.7121    0.7581    0.7344       682


** Best ** model scores - 

                  precision    recall  f1-score   support

      <software>     0.7835    0.8220    0.8023       427
           <url>     0.4667    0.5385    0.5000        13
           date>     0.5714    0.2500    0.3478        16
       <creator>     0.7778    0.6875    0.7299       112
         number>     0.7302    0.8070    0.7667       114

all (micro avg.)     0.7640    0.7786    0.7712       682



----------------------------------------------------------------------
Gloves with ELMo
max sequence length 3000, batch size 3

average over 10 folds
    macro f1 = 0.7529150918720532
    macro precision = 0.7427923520879355
    macro recall = 0.763782991202346 


** Worst ** model scores - 

                  precision    recall  f1-score   support

           date>     0.5263    0.6250    0.5714        16
      <software>     0.7363    0.7845    0.7596       427
       <creator>     0.7379    0.6786    0.7070       112
         number>     0.7109    0.7982    0.7521       114
           <url>     0.4118    0.5385    0.4667        13

all (micro avg.)     0.7188    0.7610    0.7393       682


** Best ** model scores - 

                  precision    recall  f1-score   support

           date>     0.5789    0.6875    0.6286        16
      <software>     0.7813    0.8033    0.7921       427
       <creator>     0.7830    0.7411    0.7615       112
         number>     0.7045    0.8158    0.7561       114
           <url>     0.5294    0.6923    0.6000        13

all (micro avg.)     0.7560    0.7903    0.7728       682



<tei xmlns="http://www.tei-c.org/ns/1.0"><teiHeader><fileDesc xml:id="10.1002%2Fsoej.12244" /><encodingDesc><appInfo><application version="0.5.5-SNAPSHOT" ident="GROBID" when="2019-05-09T04:11+0000"><ref target="https://github.com/kermitt2/grobid">A machine learning software for extracting information from scholarly documents</ref></application></appInfo></encodingDesc></teiHeader>
<text xml:lang="en">
<p>We identify the effect of confirmation-reports on dishonesty using data from an experiment 
where subjects are asked to roll a die and report its outcome using either a self-report or 
confirmation-report mechanism. We find that relative to self-reports, confirmation-reports 
have a positive effect on the share of subjects who report honestly. The effect on the magnitude 
of lies told depends greatly on the accuracy of the prefilled information on the confirmation-
report. We argue that these results are driven by changes in the intrinsic costs of lying induced 
by the confirmation report. </p>

<p>People often choose to misreport their private information in order to improve their own 
monetary payoffs. Common examples include used-car markets, auto-insurance, and tax returns. 
This behavior often occurs in response to one of two types of request for information. An individ-
ual may be asked to provide a self-report (e.g., what is your taxable income?) or a confirmation-
report (e.g., is your taxable income $50,000?). Because both requests ask for the same informa-
tion-the persons taxable income-we would expect a persons response to be independent of 
the form of the request. However, to the extent that intrinsic lying costs are affected by the form of 
information request, we speculate that dishonesty will be different between self-reports and confir-
mation-reports. 
1 Confirmation-reports may affect several sources of intrinsic lying costs including </p>

<p>moral-lying costs (how I see myself), social-lying costs related to changes in perception of the 
requesters information set (how others see me), and lying costs related to the mental burden of 
devising a lie. </p>

<p>* School of Public and Environmental Affairs, Indiana University, SPEA 375F, 1315 East 10th Street, Bloom-
ington, IN 47405, USA; E-mail: duncande@indiana.edu; corresponding author. 
 † Department of Economics, Hofstra University, Barnard Hall 200E, Hempstead, NY 11549, USA; E-mail: 
Danyang.Li@hofstra.edu. 
Received May 2017; accepted September 2017. 
1 Recent empirical evidence shows that intrinsic lying costs matter (Gneezy 2005; Fischbacher and F€ ollmi-Heusi 2013; </p>

<p>Abeler et al. 2014; Ruffle and Tobol 2014), and that these lying costs can be manipulated in order to affect dishonesty 
(Shu et al. 2012; Conrads et al. 2013; Erat 2013). The form of information request will most certainly affect dishonesty 
via changes in extrinsic costs. For example, the prefilled information on a confirmation-report might affect the 
respondents subjective assessment of the probability of being caught and thus the resulting expected penalty (an 
extrinsic cost of lying). We emphasize intrinsic-lying costs here because our analysis takes place in a context that is 
devoid of any extrinsic costs. </p>

<p>742 
Ó 2017 by the Southern Economic Association </p>

<p>Southern Economic Journal 2018, 84(3), 742-770 
DOI: 10.1002/soej.12244 </p>

<p>Despite a very extensive literature on lying, there is very little empirical evidence on the rela-
tive effect of these two types of reports on dishonesty (see discussion below). We contribute to the 
literature by identifying the effect of confirmation-reports on dishonesty. We answer the following 
specific research questions; are people more likely to respond honestly to confirmation-reports 
than self-reports? Also, do confirmation-reports affect the magnitude of lies told? Because it is dif-
ficult to observe lying in historical data, we answer our research questions with data collected 
from an artefactual field-experiment. We follow the traditional dishonesty literature in that we ask 
subjects to report the outcome of a six-sided die roll (Fischbacher and F€ ollmi-Heusi 2013; Jiang 
2013; Ruffle and Tobol 2014; Hao and Houser 2017). Both the roll and reporting are done in pri-
vate with no opportunity for either action to be observed by the experimenter. Subjects are paid 
according to their reported outcome, and their pay-offs are increasing in the reported die roll; with 
the exception of six, which receives a pay-off of zero. Therefore, subjects have an incentive to lie. 
Over 1400 subjects are recruited from Amazons mechanical turk, and are randomly assigned to 
one of seven groups. Subjects in group one are asked to make a self-report, while subjects in the 
remaining groups are asked to respond to a confirmation-report. The confirmation-reports are 
prefilled with a number between one and six, depending on the group, and subjects can either 
accept the report or reject it. Those who reject the report are given the opportunity to report any 
other number between one and six. 
Our analysis reveals some important findings. First, the share of subjects who report roll-
ing zero in the confirmation-report treatments is always greater than in the self-report treat-
ment. This suggests, if anything, that confirmation-reports have a positive extrinsic-margin 
effect on honesty. Second, we find that the effect on the magnitude of lies told depends on the 
accuracy of the prefilled number. At one extreme, asking subjects to confirm rolling a six, 
which has a pay-off of zero, increases the share of zeroes by approximately eight percentage 
points and reduces the share of threes and fours by three percentage points each; there is no 
effect on the share of fives. At the other extreme, asking subjects to confirm rolling a five, 
which has the highest pay-off, increases the share of subjects who lie maximally by approxi-
mately seven percentage points, while reducing the shares of ones and fours by four percentage 
points, respectively. We suspect that these effects are being driven by some combination of 
intrinsic and extrinsic responses. Last, we find that females are more honest than males, and 
that females are less likely to lie maximally under the confirmation report while there is no 
effect on maximal lying among males. 
Given the design of our experiment, we argue that these results are driven by intrinsic costs 
broadly defined to include moral lying-costs and lying costs related to the mental burden of 
whether or not and how much to lie. First, we argue that an accurately prefilled confirmation-
report increases moral lying-costs and thus reduces dishonesty since subjects who face an accurate 
confirmation-report must reject the true report and then file a false report. Concurrently, a favor-
ably inaccurate prefilled confirmation-report reduces moral lying-costs and thus increases dishon-
esty since subjects can "shift" the burden of lying onto the person who prepared the form. Second, 
the decision to lie is mentally burdensome since it generally involves two steps; the person must 
decide (i) whether or not to lie and (ii) the magnitude of the lie she wants to tell. The mental burden 
associated with these decisions is likely to be especially high given that liars generally want to 
maintain the perception of honesty (Greenberg, Smeets, and Zhrakhovska 2015; Hao and Houser 
2017). In cases like these, people often turn to rules-of-thumb, which makes them susceptible to 
decision-making biases. Therefore, a subject might more readily accept an accurate or favorably 
inaccurate confirmation-report because it is easier than having to make the lying decision herself. </p>

<p>Effect of Confirmation-Reports on Dishonesty </p>

<p>
The presence of prefilled information on confirmation-reports might also change 
respondents beliefs about the requesters information set. 
2 Therefore, it is also possible that our </p>

<p>results are partly driven by another type of intrinsic cost related to the shame of being identified as 
a liar. However, the experiment is conducted in the field, and while subjects know they are partici-
pating in an academic study, they do not know that the die-rolling exercise is part of an experi-
ment. 
3 Furthermore, we emphasize the fact that we have no way of observing their die roll. This </p>

<p>suggests that our results are not being driven by such social costs related to changes in perception 
about the experimenters information set. 
Our article makes several contributions to the academic literature and policy discussions. 
First, to our knowledge, we are the first to identify the effect of confirmation-reports on dishon-
esty in an environment where extrinsic costs do not matter. Fonseca and Grimshaw (2017) and 
Kotakorpi and Laamanen (2015) estimate the compliance effect of administering an income tax 
with prepopulated tax forms rather than blank tax forms using data from a field experiment and a 
natural experiment, respectively. 
4 Both studies find that a favorably inaccurate prefilled tax form </p>

<p>increases noncompliance on the nonprefilled items. This finding is similar to our result where over-
stating the outcome of the die roll increases the share of subjects who confirm that die roll. Because 
these studies focus on tax evasion, the observed responses are driven by both extrinsic (audit and 
fine) and intrinsic costs. Unlike these two articles, we are able to show that confirmation-reports 
affect dishonesty even in the absence of extrinsic costs. 
We also add to the extensive literature on lying. Existing studies have explored several impor-
tant aspects of dishonesty including the role of shame (Greenberg, Smeets, and Zhrakhovska 
2015), guilt (Charness and Dufwenberg 2006; Battigalli, Charness, and Dufwenberg 2013), per-
ceived unfairness (Houser, Vetter, and Winter 2012), gender (Dreber and Johannesson 2008; 
Muehlheusser, Roider, and Wallmeier 2015), magnitude of pay-off (Suri et al. 2011; Fischbacher 
and F€ ollmi-Heusi 2013), time preference (Ruffle and Tobol 2014), education (Ruffle and Tobol 
2016), morality (Shu et al. 2012), and lying costs more broadly (Gneezy 2005; Abeler, Becker, and 
Falk 2014; Kajackaite and Gneezy 2017). A common feature of all of these studies is that they ask 
subjects to make self-reports using blank forms. We add to this literature by showing that the form 
of the request matters. Requesting information via confirmation-reports influences lying costs and 
thus increases or decreases dishonesty depending on the accuracy of the prefilled information on 
the reports. This finding is similar to studies that show that dishonesty can be influenced by chang-
ing lying costs either by having people commit to telling the truth (Shu et al. 2012), delegating the 
reporting responsibility (Erat 2013), or team incentives (Conrads et al. 2013). 
Understanding the effect of self and confirmation reports on dishonesty is important for 
everyday life. It is particularly relevant in instances where people are hoping to obtain correct 
information but the provider of the information faces little or no extrinsic costs. For example, 
used-car markets and students giving excuses for missing exams or assignments. Other </p>

<p>2 On the one hand, a correctly prefilled report might cause people to believe that their private information is known to </p>

<p>the requester. In this case, the social cost of lying increases because the person believes her decision to be dishonest will 
be observed by the requester; that is, she will be a known liar. On the other hand, an inaccurate confirmation-report 
might confirm the respondents belief that the requester does not know the respondents true information. In this case, 
the social cost of lying decreases because the decision to lie remains unknown to the requester. 
3 The dishonesty experiment was conducted after the subjects had completed a survey about public opinion toward road </p>

<p>user-charges. See implementation subsection for details. 
4 Prepopulated tax forms require taxpayers to complete their annual tax reconciliation by filing a form that is prefilled </p>

<p>with information available to the tax administrator, and is therefore comparable to a confirmation-report. </p>

<p> 
Denvil Duncan and Danyang Li </p>

<p>applications include state-provided services for which there are no penalties for lying. 
5 There is </p>

<p>also an obvious application to tax administration. 
6 However, we are careful in extrapolating our </p>

<p>results to this context because cheating on taxes is a risky decision that includes extrinsic costs. 
Still, our results suggest that the type of form used in the reconciliation process matters for compli-
ance, and that the effect of the form will depend crucially on the accuracy of the information avail-
able to the administrator. Policymakers who wish to prefill tax returns for taxpayers for whom 
true income is uncertain should prefill forms with a higher rather than lower numbers to reduce 
noncompliance. However, as a matter of practical policy making, it might not be ethical for the 
government to submit prefilled forms with information that is known to be inaccurate. Therefore, 
policymakers who implement prepopulated forms often limit them to taxpayers with known infor-
mation, and our results also support this strategy. </p>

<p>7 </p>

<p>The remainder of the article is organized as follows. First, we describe the experimental 
design. This is followed by a description of our results, discussion and conclusion. </p>

<p>2. Design and Implementation </p>

<p>Our primary objective is to determine if, relative to self-reports, confirmation-reports lead to 
more liars and larger lies in a context where extrinsic costs do not matter. This section describes 
the experimental design used to answer our research question. </p>

<p>Experimental Design </p>

<p>The experiment is completed in two steps. First, we instruct subjects to roll a six-sided die 
and make a note of the number thrown on their first attempt. Subjects are told that they can throw 
the die as many times as they want, but only the first throw counts. Second, subjects are asked to 
report the outcome of their die roll. The subjects are told that we have no way of knowing the out-
come of the die roll, and that their payment will be based solely on the number they report follow-
ing the schedule in Table 1. 
8 The information in Table 1 is shown to the subjects twice; when they </p>

<p>read the instructions for the experiment and again when they make their reporting decisions. </p>

<p>5 One example would be parks for which entry fees are conditional on location of residence. Example, the Eagle Creek </p>

<p>Park in Indianapolis, Indiana charges a lower fee for residence of Marion county. However, there is no process in place 
to verify patrons county of residence. 
6 While most tax administrators implement tax reconciliations with blank-tax forms, others use prepopulated forms. </p>

<p>Prepopulated tax forms are used in Finland, Denmark, Sweden, Norway. The United Kingdom is currently consider-
ing the adoption of prepopulated tax forms. Although there has been discussions about the merits of a prepopulated 
tax form in the United States, the State of California is the only U.S. government to have implemented them under 
their ready-return initiative. <rs type="software">ReadyReturn</rs> has since been cancelled, but its primary feature-prepopulating tax forms 
with pre-existing information-is still available with <rs type="software">CalFile</rs>. 
7 Of course, this strategy does not preclude the possibility of increased noncompliance among taxpayers who have only </p>

<p>verifiable income in the current period, but earn income from nonverifiable sources in the future. Confirmation-reports 
could also increase noncompliance by inducing taxpayers to reduce their verifiable income and increase their nonverifi-
able income. 
8 Notice that the payment for rolling a six is zero as in Fischbacher and F€ ollmi-Heusi (2013). Because the pay-off for </p>

<p>rolling a six is zero, we recode the outcome six to be zero. This adjustment is made to the data for all tables and figures 
reported in the article. </p>

<p>Effect of Confirmation-Reports on Dishonesty </p>

<p>
This design conforms with the previous literature; for example, Fischbacher and F€ ollmi-
Heusi (2013); Ruffle and Tobol (2014). The main difference between our design and that of the 
existing literature is in the way subjects are asked to report the outcome of the die roll. The previ-
ous literature simply asked subjects to self-report the outcome of the die roll. We add to this by 
also asking some subjects to provide confirmation-reports. Subjects are randomly assigned to one 
of seven groups; one self-report treatment and six confirmation-report treatments. The only differ-
ence between the self-report treatment and the confirmation-report treatment is in step two where 
subjects are asked to report the die roll outcome. </p>

<p>Self-Report Treatment </p>

<p>Subjects in the Self Report Treatment (SRT) are shown an empty text box and are asked to 
report the outcome of their first die roll (see Figure 1). We again show subjects Table 1 so that the 
relationship between the reported number and the bonus payment remains salient. We also remind 
them that we have no way of knowing the number that they actually rolled on the die. The session 
ends when a subject submits the reported die roll. </p>

<p>Confirmation-Report Treatment </p>

<p>Subjects in the Confirmation Report Treatments (CRT) are randomly assigned to one of 
six subgroups. Subjects in each group are shown a text box that is prefilled with a fixed num-
ber; either 1, 2, 3, 4, 5, or 6 depending on their assigned group (see Figure 2). In other words, 
every subject assigned to CRT0 is shown a text box that is prefilled with the number 6. Simi-
larly, every subject assigned to CRT5 is shown a text box that is prefilled with the number 5, 
and so on. Subjects are asked to confirm whether the prefilled number is the number on the 
face of their first die roll. The prefilled number is reported and the session ends if they </p>

<p>Table 1. Bonus Pay-Off Schedule </p>

<p>Number Reported 
1 
2 
3 
4 
5 
6 </p>

<p>Resulting pay-off 
$0.10 
$0.20 
$0.30 
$0.40 
$0.50 
$0.00 </p>

<p>Figure 1. Die Reporting Screenshot for Self-Report Treatment. [Color figure can be viewed at wileyonlineli-
brary.com] </p>

<p> 
Denvil Duncan and Danyang Li </p>

<p>respond "yes." Subjects who respond "no" are given an opportunity to self-report a different 
number. 
We use a between-subject design, where each subject only participates in one of the seven 
treatments, and makes her rolling and reporting decisions once. </p>

<p>Implementation </p>

<p>Because the design is simple and can be completed in only a few minutes, we implement the 
experiment online with the aid of Amazons Mechanical Turk (Mturk). 
9 Mturk is an online labor </p>

<p>market where job offers are posted and workers choose jobs for payment. It has numerous benefits 
for running experiments, including access to a large stable subject pool, diverse subject back-
ground, and low costs (Horton and Chilton 2010; Paolacci, Chandler, and Ipeirotis 2010; Mason 
and Suri 2012). Furthermore, the behavior of online workers has been shown to be comparable to 
those of subjects in laboratory studies (Paolacci, Chandler, and Ipeirotis 2010; Buhrmester, 
Kwang, and Gosling 2011; Horton, Rand, and Zeckhauser 2011; Suri et al. 2011). 
We create a survey-based human intelligence task (HIT) on Mturk (see Figure 3) and 
provide a link to our own website where subjects are able to complete the survey and a bonus 
task. 
10 Following the survey, subjects are asked to complete a bonus task, which involves </p>

<p>rolling a six-sided die and reporting the outcome. Subjects receive task instructions shown 
in Figures 4 and 5. They are told that the amount of the bonus payment is determined by 
the reported die roll according to Table 1. A link to the website random.org, which allows 
people to roll virtual die, is embedded into our website. Subjects are instructed to click on 
the link in order to roll the die, and to return to our website to report the outcome of the die 
roll. We make it explicitly clear that our website is not affiliated with random.org, so the </p>

<p>Figure 2. Die Reporting Screenshot for Confirmation-Report Treatments. [Color figure can be viewed at 
wileyonlinelibrary.com] </p>

<p>9 Subjects took an average of nine minutes to complete both stages of the experiment, and 50% of subjects completed </p>

<p>the experiment in less than 5 minutes and 20 seconds. 
10 We created the external website for the sole purpose of hosting the survey and bonus task. The survey includes ques-</p>

<p>tions about road mileage user-fees, number of miles driven, age, gender, race, and education. Subjects are paid a flat 
participation fee for completing the survey. The experiment was done in December 2015 and January of 2016. </p>

<p>Effect of Confirmation-Reports on Dishonesty </p>

<p>
actual outcome of the die roll is not known to us. Subjects are told that we can only observe 
the number that they report on our website. Subjects are shown an ID code after submitting 
their reported die roll, and are told to report this code on the <rs type="software">Mturk</rs> website in order for us 
to process their bonus payment. 
<rs type="software">Mturk</rs> is especially advantageous for our study because subjects can be assured that 
we have no way of telling whether they are lying or not. Subjects complete the tasks in their 
own environment immune to the influence from other participants or the experimenters. 
Therefore, the design does not involve any social interactions. Additionally, the experiment 
does not include a compliance mechanism; that is, no audit, no penalty, and no opportunity </p>

<p>Figure 3. <rs type="software">mTurk</rs> HIT. [Color figure can be viewed at wileyonlinelibrary.com] </p>

<p>Figure 4. Bonus Task Instructions Part I. </p>

<p> 
Denvil Duncan and Danyang Li </p>

<p>for the experimenter to observe a subjects actions. This implies that the actual and 
expected extrinsic costs of lying are zero. We argue that these two characteristics of the 
experimental design implies that the decision to be dishonest in our experiment depends 
only on a tradeoff between the external monetary benefits and the internal costs of the dis-
honest act. </p>

<p>3. Results </p>

<p>This section begins with a description of our data. We then describe dishonesty in the self-report treat-
ment, which serves as our baseline. Next, we describe dishonesty in the confirmation-report treatments fol-
lowed by additional analyses that account for gender effects as well as dishonesty among subjects whom we 
know rolled the virtual die versus those who probably did not roll a die. </p>

<p>Data </p>

<p>Summary Statistics </p>

<p>A total of 1475 subjects participated in the experiment, which translates into approximately 
200 subjects per treatment. Subjects took an average of nine minutes to complete the survey and 
bonus task, and were paid an average of $0.81; this is equivalent to an hourly wage of approxi-
mately $5.40. Our hourly wage is comparable to that of other surveys conducted on Mturk (e.g., 
Kuziemko et al. 2015 paid $6.00 per hour), and much higher than the estimated reservation wage 
of Mturk workers; $1.38 (Horton and Chilton 2010). 
Table 2 shows that CRT treatments CRT0, CRT3, CRT4, and CRT5 are balanced with 
respect to age, gender, race, and education, relative to the control group (SRT). CRT1 is also well </p>

<p>Figure 5. Bonus Task Instructions Part II. [Color figure can be viewed at wileyonlinelibrary.com] </p>

<p>Effect of Confirmation-Reports on Dishonesty </p>

<p>
balanced compared to SRT except that CRT1 has slightly less females. The treatment group CRT2 
has fewer females and whites and more college educated subjects. </p>

<p>Uniformity of Random.org </p>

<p>Since subjects rolled a virtual die through random.org, it is important to establish that the vir-
tual die on this website is fair. Because each group has 203-225 observations, we provide evidence 
that the virtual die is fair by collecting the outcome of approximately 210 die rolls from random.org 
and present the resulting distribution in Figure 6. The evidence presented in Figure 6 shows that 
the virtual die is fair. We cannot reject the null that the distribution obtained from random.org 
is uniform: p value from Kolmogorov-Smirnov two-sample test is 0.97 and p values from </p>

<p>Table 2. Summary of Demographic Variables </p>

<p>Variables 
SRT 
CRT:0 
CRT:1 
CRT:2 
CRT:3 
CRT:4 
CRT:5 
Total </p>

<p>Age 
34.50 
34.42 
35.04 
32.96 
34.00 
35.87 
35.15 
34.58 
[0.85] 
[0.90] 
[0.10] 
[0.48] 
[0.16] 
[0.98] 
Female 
0.50 
0.48 
0.41 
0.37 
0.49 
0.46 
0.42 
0.45 
[0.57] 
[0.05] 
[0.01] 
[0.84] 
[0.42] 
[0.11] 
White 
0.83 
0.85 
0.78 
0.75 
0.78 
0.80 
0.79 
0.80 
[0.55] 
[0.21] 
[0.05] 
[0.16] 
[0.38] 
[0.22] 
Wage 
0.82 
0.80 
0.80 
0.80 
0.80 
0.82 
0.84 
0.81 
[0.21] 
[0.27] 
[0.10] 
[0.14] 
[0.84] 
[0.25] 
College 
0.46 
0.48 
0.52 
0.54 
0.43 
0.53 
0.51 
0.50 
[0.65] 
[0.18] 
[0.08] 
[0.51] 
[0.17] 
[0.30] </p>

<p>Reported is the mean for the respective demographic variables by treatment. We report mean shares unless otherwise 
indicated. College indicates completion of college degree or higher. SRT is self-report treatment, and CRT is 
confirmation-report treatment. p values from the Wilcox-rank sum test for differences in means between SRT and 
each CRT treatment group are reported in square brackets. </p>

<p>16.59 </p>

<p>18.01 </p>

<p>19.91 </p>

<p>15.17 </p>

<p>17.06 </p>

<p>13.27 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Percent </p>

<p>0 
1 
2 
3 
4 
5 
Value Observed </p>

<p>Figure 6. Distribution of Virtual Die Roll Outcomes. 
Notes: Reported is the distribution of die outcomes from the website Random.org. Because the pay-off for 
rolling a 6 is zero, we recode the outcome 6 as 0. The horizontal line indicates 16.67%. [Color figure can be 
viewed at wileyonlinelibrary.com] </p>

<p> 
Denvil Duncan and Danyang Li </p>

<p>two-sided binomial tests that the share of each reported number is equal to 16.67% are all greater 
than 0.2. We take this as evidence that each of the observed distributions from our experiment 
should be uniform if subjects report honestly. </p>

<p>Self-Report Treatment Results </p>

<p>Result 1. We Find Strong Evidence for an Overall Pattern of Dishonesty Among Subjects </p>

<p>The distribution of reported die rolls in Figure 7 indicates the presence of lying in SRT. Sub-
jects report low-paying numbers at frequencies below 16.67% and report high-paying numbers at 
frequencies above 16.67%, which is indicative of dishonesty. A Kolmogorov-Smirnov two-sample 
test confirms that the observed distribution is statistically different from a uniform distribution 
(pvalue &lt; 1%). This is further supported by a two-sided binomial test that the share of subjects 
reporting each number is equal to 16.67%; we can reject the null that the share of reported 0, 2 and 
5 is 16.67% at the 1% level. However, we cannot reject that the share of 1, 3, and 4 is 16.67%. This 
finding implies that some subjects lied about their die roll and reported higher numbers than what 
they actually rolled. 
Since there is no incentive for people to lie for lower payoffs, it is reasonable to assume that 
subjects who report a zero payoff are honest. In our experiment, 7.4% of subjects in SRT report a 
die roll of 6, which results in a zero payoff. Following Fischbacher and F€ ollmi-Heusi (2013), we 
use this information to estimate the percentage of unconditionally honest subjects to be approxi-
mately 44% (57:4% Ã 6). 
11 In other words, we find that 44% of subjects are honest despite the fact </p>

<p>7.389 </p>

<p>13.79 </p>

<p>9.852 </p>

<p>17.24 </p>

<p>19.7 </p>

<p>32.02 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Percent </p>

<p>0 
1 
2 
3 
4 
5 
Value Reported </p>

<p>Panel A: SRT </p>

<p>Figure 7. Distribution of Reported Die Outcomes in SRT. 
Notes: Reported is the distribution of die outcomes for the self-report (SRT). Because the pay-off for rolling a 
6 is zero, we recode the outcome 6 as 0. The horizontal line indicates 16.67%. [Color figure can be viewed at 
wileyonlinelibrary.com] </p>

<p>11 This is based on the assumption that unconditionally honest subjects in fact rolled a uniform distribution of numbers. </p>

<p>To the extent that some subjects reported a six despite rolling another number, then this estimate represents an upper 
bound on the share of unconditionally honest subjects. </p>

<p>Effect of Confirmation-Reports on Dishonesty </p>

<p>
that lying is both unobservable and profitable. The SRT results also provide evidence of maximal 
lying. We find that 32% of the subjects in SRT report a payoff of 5, which is statistically greater 
than the expected probability of 1/6. This implies that some subjects lied to maximize their payoffs. 
Since there is no incentive for subjects who rolled 5 to report a lower payoff, we estimate the per-
centage of maximal liars to be 18% (5ð32216:7Þ Ã ð6=5Þ). </p>

<p>Confirmation-Report Treatment </p>

<p>Recall that the confirmation treatment is divided into six subgroups where every subject in a 
given subgroup is asked to confirm the same prefilled number. We therefore are able to disaggre-
gate the CRT results into its component groups and compare each subgroup to SRT. </p>

<p>Result 2. The Disaggregated CRT Data Show that Dishonesty Persists Regardless of the Pre-
filled Number </p>

<p>Figure 8 presents the distribution of reported payoffs for each CRT subgroup. 
12 A </p>

<p>Kolmogorov-Smirnov two-sample test confirms that the observed distributions in Figure 8 are 
statistically different from a uniform distribution (pvalues &lt; 5%), which suggests the presence of 
lying across all groups. Visual inspection suggests that dishonesty is influenced by the prefilled 
number. For example, the share of maximal liars is highest in Panels A, B, and F, where subjects </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Percent </p>

<p>Panel A: CRT0 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Panel B: CRT1 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Panel C: CRT2 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Percent </p>

<p>0 1 2 3 4 5 
Value Reported </p>

<p>Panel D: CRT3 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>0 
1 
2 
3 
4 
5 
Value Reported </p>

<p>Panel E: CRT4 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>0 
1 
2 
3 
4 
5 
Value Reported </p>

<p>Panel F: CRT5 </p>

<p>Figure 8. CRT Conditional on Prepopulated Number. 
Notes: Reported is the distribution of die outcomes for the CRT. Because the pay-off for rolling a 6 is zero, 
we recode the outcome 6 as 0. The horizontal line indicates 16.67%. [Color figure can be viewed at wileyonli-
nelibrary.com] </p>

<p>12 Recall that the only difference between subgroups is the prefilled number on the confirmation report. </p>

<p> 
Denvil Duncan and Danyang Li </p>

<p>are asked to confirm zero, one, and five, respectively. We also observe that the share of partial liars 
(based solely on the share of reported fours) is highest in Panels C, D, and E where subjects are 
asked to confirm two, three, and four, respectively. Additionally, the observed distribution that 
most closely resembles a uniform distribution is Panel A where subjects were asked to confirm roll-
ing a 6. Only the reported share of twos and fives in Panel A of Figure 8 can be distinguished from 
16.67% according to a two-sided binomial test, while at least four of the six bars in the remaining 
panels of Figure 8 can be distinguished from 16.67%. </p>

<p>Result 3. The Share of Subjects Confirming a Prefilled Number Increases in the Pay-off Asso-
ciated with That Number </p>

<p>Figure 8 also shows that the share of subjects confirming a given prefilled number is increas-
ing in the prefilled number, and almost always greater than the expected share of 16.67%. To see 
this more clearly, we present-in Figure 9-the share of subjects in each group who confirm the 
number they are shown on their prefilled report. We refer to these subjects as confirmers. Figure 9 
shows clearly that subjects are more likely to confirm a one than a zero, and more likely to confirm 
a two than a one, and so on. Notice that this finding is inconsistent with honest reporting. In other 
words, the share of confirmers should be equal to 16.67% if subjects are reporting honestly. </p>

<p>Result 4. The Share of Subjects Confirming a Prefilled Number is Greater than the Share of 
Subjects Who Self-Report That Same Prefilled Number </p>

<p>Relative to SRT (see Figure 7), Figure 9 shows that the share of subjects confirming a given 
prefilled number is greater than the share of subjects who self-report that same number. To illus-
trate this treatment effect more clearly, we compare each CRT sub-group in Figure 8 to SRT in </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Percent </p>

<p>CRT:0 
CRT:1 
CRT:2 
CRT:3 
CRT:4 
CRT:5 </p>

<p>CRT Treatment </p>

<p>Figure 9. CRT Share of Confirmers Conditional on Prepopulated Number. 
Notes: Reported is the share of subject who confirm the prepopulated number on their confirmation report 
for each CRT treatment. The horizontal line indicates 16.67%. [Color figure can be viewed at wileyonlineli-
brary.com] </p>

<p>Effect of Confirmation-Reports on Dishonesty </p>

<p>
Figure 7. For example, we identify the treatment effect of CRT0 by subtracting the share of sub-
jects who self-report each number in Figure 7 from the share of subjects who report the respective 
number in Panel A of Figure 8. We repeat this for each panel in Figure 8 in order to identify the 
treatment effect of the other prefilled numbers. The results from this exercise are reported in Fig-
ure 10; each panel reports the treatment effect for a different CRT subgroup. 
Figure 10 shows that relative to SRT, confirmation reports increase the share of subjects who 
report a given prefilled number by 6.5-11.8 percentage points across all groups. These effects are 
both economically meaningful and statistically different from zero, and is further evidence that 
confirmation reports influence reporting behavior. </p>

<p>Result 5. The Extensive and Intensive Margin Lying Responses Vary Across Subgroups </p>

<p>An interesting question to ask at this point is whether or not confirmation-reports affect the 
share of honest subjects, and the share of partial and maximal liars. The results in Figure 10 shed 
some light on this question. First, we find evidence of a positive extensive-margin effect; the 
confirmation-reports caused an increase in the share of honest subjects. The treatment effects in 
Panel A of Figure 10 show that the share of zeroes increases, the share of threes and fours 
decreases, and there is no economically significant effect on any other number. Since no one has 
an incentive to report a smaller number than she actually rolled, this suggests that the </p>

<p>−12 
−8 −4 0 </p>

<p>4 
8 12 </p>

<p>Percent </p>

<p>0 
1 
2 
3 
4 
5 </p>

<p>Panel A: CRT0 </p>

<p>−12 
−8 −4 0 </p>

<p>4 
8 12 </p>

<p>0 
1 
2 
3 
4 
5 </p>

<p>Panel B: CRT1 </p>

<p>−12 −8 −4 0 </p>

<p>4 
8 12 </p>

<p>0 
1 
2 
3 
4 
5 </p>

<p>Panel C: CRT2 </p>

<p>−12 −8 −4 </p>

<p>0 </p>

<p>4 
8 12 </p>

<p>Percent </p>

<p>0 
1 
2 
3 
4 
5 </p>

<p>Value Reported </p>

<p>Panel D: CRT3 </p>

<p>−12 −8 −4 </p>

<p>0 </p>

<p>4 
8 12 </p>

<p>0 
1 
2 
3 
4 
5 </p>

<p>Value Reported </p>

<p>Panel E: CRT4 </p>

<p>−12 −8 −4 </p>

<p>0 </p>

<p>4 
8 12 </p>

<p>0 
1 
2 
3 
4 
5 </p>

<p>Value Reported </p>

<p>Panel F: CRT5 </p>

<p>Figure 10. SRT versus CRT Treatment Effect Conditional on Prepopulated Number. 
Notes: Reported is the treatment effect for each of the CRT. For each panel, each bar represents the share of 
subjects reporting that number in the respective CRT minus the share of subjects reporting that number in 
SRT. Because the pay-off for rolling a 6 is zero, we recode the outcome 6 as 0. </p>

<p> 
Denvil Duncan and Danyang Li </p>

<p>confirmation report in CRT0 reduces the share of partial liars, and increases the share of subjects 
who report honestly by 8 percentage points. </p>

<p>13 </p>

<p>The treatment effect in each of the remaining confirmation-report treatments reflect both 
extensive and intensive margin responses, and it is difficult to separate the two because we do 
not know the true outcome for each subject. For example, we observe a significant reduction 
in the share of reported threes and fours coupled with an increase in the share of reported ones 
in CRT1 (Panel B of Figure 10). This suggests that subjects who would have self-reported 
threes and fours report a one when presented with a CRT1. This behavior is consistent with 
two possible explanations related to extensive and intensive margin lying-responses. On the 
one hand, it is possible that subjects who rolled a one and would have lied by self-reporting a 
three now report honestly, thus reflecting an extensive margin response. On the other hand, 
CRT1 could also reflect an intensive margin response in the sense that subjects who rolled a 
six now lie less intensely by reporting one instead of a three. Our data do not allow us to distin-
guish between these two possible effects, but we suspect that some combination of the two is at 
play. </p>

<p>Rollers </p>

<p>Subjects who are committed to lying might find it pointless to roll the die since their reported 
outcome will be independent of the die roll. However, it is usually impossible to tell if subjects 
rolled the die because they make their die roll and reporting decisions in private. This information 
is important in our context since it is possible that subjects who are committed liars respond differ-
ently to the treatment than other subjects. Therefore, we designed the experiment such that we can 
identify subjects who clicked on the die-roll link. We refer to those subjects who clicked on the link 
as "rollers," and those who did not click on the link as "non-rollers." 
14 This section describes how </p>

<p>our results are affected when we cut the data by roller status. 
Table 4 shows that approximately 36% of subjects in both SRT and CRT are nonrollers; that 
is, they did not click on the die-roll link before making their reporting decision. With the exception 
of CRT1 (30%) and CRT2 (40%), this share is fairly flat across CRT subgroups. Additionally, there 
is no difference in the likelihood of being a nonroller across gender or race. Younger subjects are 
more likely to be nonrollers, but the estimated effect is not economically meaningful. The only 
demographic characteristic that is strongly correlated with nonroller is education level; the likeli-
hood of being a nonroller decreases with education level. 
15 These differences are not worrisome </p>

<p>since the treatment groups are balanced with respect to education level. However, given that each </p>

<p>13 This is based on three reasonable assumptions regarding behavior in Panel A; (i) the share of unconditionally honest </p>

<p>subjects is 7.4%, just as in SRT, (ii) the confirmation-report does not affect the propensity to report any of the other 
numbers honestly, and (iii) subjects who report a zero payoff are honest. The first assumption follows from randomi-
zation of subjects into groups. The fact that the share of zeroes in each panel of Figure 10 is not statistically different 
from 7.4% is further evidence that the share of unconditionally honest subjects is at least 7.4% across all groups. The 
second assumption is supported by the treatment effects in Panel A of Figure 10. 
14 We are only able to tell if the link was clicked; we cannot observe the outcome of the die roll. Also, we cannot rule out </p>

<p>the possibility that nonrollers actually rolled a die. For example, it is possible that they simply bypassed our link to 
the virtual die, or that they rolled their own physical die. As mentioned before, our inability to observe the die out-
come was made clear to subjects. 
15 The share of nonrollers among subjects with a graduate degree is 25%. Relative to graduate degree holders, subjects </p>

<p>with a bachelors degree, some college, and high school diploma are 11%, 10%, and 15%, respectively, more likely to be 
nonrollers. These differences are both economically and statistically significant. </p>

<p>Effect of Confirmation-Reports on Dishonesty </p>

<p>
group has approximately 200 observations, the number of nonrollers ranges from 62 to 84. As a 
result, we urge caution when interpreting the results in this section. </p>

<p>Result 6. Subjects Who Clicked on the Die-Roll Link are More Honest than Subjects Who 
Did Not Click on the Link </p>

<p>Figure 11 presents the distribution of reported die rolls for SRT conditional on roller status. 
Although the observed distributions are all statistically different from a uniform distribution, the 
results clearly suggest that rollers are more honest than nonrollers. 
16 In particular, relative to non-</p>

<p>rollers, rollers report a greater share of zeroes and a lower share of fives. The difference between 
rollers and nonrollers in the propensity to lie is also apparent in Figures 12 and 13, which report 
results for rollers and nonrollers in the CRT treatments, respectively. Again, while the observed 
distributions among rollers suggests the presence of lying, we find even stronger evidence of lying 
among nonrollers. </p>

<p>Result 7. The Estimated Treatment Effect of CRT is Much Stronger Among Nonrollers </p>

<p>As in confirmation-report treatment section, the results presented in Figures 14 and 15 
show that the treatment effect depends on the prefilled number. Subjects are more likely to con-
firm the prefilled number than to self-report that same number. However, this effect is much </p>

<p>8.527 </p>

<p>16.28 </p>

<p>11.63 </p>

<p>17.05 </p>

<p>19.38 </p>

<p>27.13 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Percent </p>

<p>0 
1 
2 
3 
4 
5 
Value Reported </p>

<p>Panel A: SRT Rollers </p>

<p>5.405 </p>

<p>9.459 </p>

<p>6.757 </p>

<p>17.57 </p>

<p>20.27 </p>

<p>40.54 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>0 
1 
2 
3 
4 
5 
Value Reported </p>

<p>Panel B: SRT NonRollers </p>

<p>Figure 11. Roller versus Nonrollers in SRT. 
Notes: Reported is the distribution of die outcomes for the self-report (SRT) treatment for rollers and nonroll-
ers. Because the pay-off for rolling a 6 is zero, we recode the outcome 6 as 0. The horizontal line indicates 
16.67%. </p>

<p>16 Kolmogorov-Smirnov two-sample test confirms that the observed distributions are statistically different from a uni-</p>

<p>form distribution (pvalue &lt; 1%). </p>

<p>756 
Denvil Duncan and Danyang Li </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Percent </p>

<p>Panel A: CRT0 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Panel B: CRT1 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Panel C: CRT2 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Percent </p>

<p>0 1 2 3 4 5 
Value Reported </p>

<p>Panel D: CRT3 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>0 
1 
2 
3 
4 
5 
Value Reported </p>

<p>Panel E: CRT4 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>0 
1 
2 
3 
4 
5 
Value Reported </p>

<p>Panel F: CRT5 </p>

<p>Figure 12. Rollers by CRT Subgroup. 
Notes: Reported is the distribution of die outcomes for the CRT among rollers. Because the pay-off for rolling 
a 6 is zero, we recode the outcome 6 as 0. The horizontal line indicates 16.67%. </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Percent </p>

<p>Panel A: CRT0 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Panel B: CRT1 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Panel C: CRT2 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Percent </p>

<p>0 1 2 3 4 5 
Value Reported </p>

<p>Panel D: CRT3 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>0 
1 
2 
3 
4 
5 
Value Reported </p>

<p>Panel E: CRT4 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>0 
1 
2 
3 
4 
5 
Value Reported </p>

<p>Panel F: CRT5 </p>

<p>Figure 13. Nonrollers by CRT Subgroup. 
Notes: Reported is the distribution of die outcomes for the CRT among nonrollers. Because the pay-off for 
rolling a 6 is zero, we recode the outcome 6 as 0. The horizontal line indicates 16.67%. [Color figure can be 
viewed at wileyonlinelibrary.com] </p>

<p>Effect of Confirmation-Reports on Dishonesty </p>

<p>
stronger among nonrollers. 
17 Figure 14 also shows that, relative to SRT, a confirmation-report </p>

<p>prefilled with zero or one has very little effect on the reporting behavior of rollers; differences are 
indistinguishable from zero. At the same time, a prefilled report with two, three, or four reduces 
maximal lying while a report prefilled with five increases maximal lying. 
We find somewhat similar results for nonrollers in Figure 15. Prefilling the report with 
a number less than five reduces maximal lying, but by larger amounts compared to rollers. 
Interestingly, prefilling the report with a five increases maximal lying by a smaller amount 
compared to rollers; approximately 5.5 points among nonrollers compared to approximately 
nine points among rollers. 
Overall, the results show that while the treatment affected both groups in similar ways, it had 
a much larger effect on nonrollers. We discuss the implications of this finding for our main results 
in section 4. </p>

<p>Gender Effect </p>

<p>A common finding in the literature is that males tend to be more dishonest than females 
(Dreber and Johannesson 2008; Childs 2012; Erat 2013; Muehlheusser, Roider, and Wallme-
ier 2015). We explore whether this finding holds in our setting. First, we note that while each </p>

<p>−12 −6 </p>

<p>0 </p>

<p>6 </p>

<p>12 </p>

<p>18 </p>

<p>Percent </p>

<p>0 
1 
2 
3 
4 
5 </p>

<p>Panel A: CRT0 </p>

<p>−12 −6 </p>

<p>0 </p>

<p>6 </p>

<p>12 </p>

<p>18 </p>

<p>Percent </p>

<p>0 
1 
2 
3 
4 
5 </p>

<p>Panel B: CRT1 </p>

<p>−12 −6 </p>

<p>0 </p>

<p>6 </p>

<p>12 </p>

<p>18 </p>

<p>Percent </p>

<p>0 
1 
2 
3 
4 
5 </p>

<p>Panel C: CRT2 </p>

<p>−12 −6 </p>

<p>0 </p>

<p>6 
12 18 </p>

<p>Percent </p>

<p>0 
1 
2 
3 
4 
5 </p>

<p>Value Reported </p>

<p>Panel D: CRT3 </p>

<p>−12 −6 </p>

<p>0 </p>

<p>6 
12 18 </p>

<p>Percent </p>

<p>0 
1 
2 
3 
4 
5 </p>

<p>Value Reported </p>

<p>Panel E: CRT4 </p>

<p>−12 −6 </p>

<p>0 </p>

<p>6 
12 18 </p>

<p>Percent </p>

<p>0 
1 
2 
3 
4 
5 </p>

<p>Value Reported </p>

<p>Panel F: CRT5 </p>

<p>Figure 14. Treatment Effect of CRT: Rollers. 
Notes: Reported is the treatment effect for each of the CRT among rollers. For each panel, each bar represents 
the share of subjects reporting that number in the respective CRT minus the share of subjects reporting that 
number in SRT. Because the pay-off for rolling a 6 is zero, we recode the outcome 6 as 0. </p>

<p>17 The effect is only distinguishable from zero for prefilled number zero, three, four, and five. </p>

<p> 
Denvil Duncan and Danyang Li </p>

<p>group has more males than females, gender is fairly balanced within and between groups (see 
Table 3). </p>

<p>Result 8. Men are More Dishonest than Women in Both SRT and CRT </p>

<p>Figure 16 shows the observed distributions by gender for SRT. Visually, the distributions sug-
gest the presence of lying. However, a Kolmogorov-Smirnov two-sample test rejects the null that 
the male distribution is uniform (p values &lt; 51%), but marginally fails to reject uniformity for </p>

<p>−12 −6 </p>

<p>0 </p>

<p>6 </p>

<p>12 </p>

<p>18 </p>

<p>Percent </p>

<p>0 
1 
2 
3 
4 
5 </p>

<p>Panel A: CRT0 </p>

<p>−12 −6 </p>

<p>0 </p>

<p>6 </p>

<p>12 </p>

<p>18 </p>

<p>Percent </p>

<p>0 
1 
2 
3 
4 
5 </p>

<p>Panel B: CRT1 </p>

<p>−12 −6 0 </p>

<p>6 12 </p>

<p>18 </p>

<p>Percent </p>

<p>0 
1 
2 
3 
4 
5 </p>

<p>Panel C: CRT2 </p>

<p>−12 −6 </p>

<p>0 </p>

<p>6 
12 18 </p>

<p>Percent </p>

<p>0 
1 
2 
3 
4 
5 </p>

<p>Value Reported </p>

<p>Panel D: CRT3 </p>

<p>−12 −6 0 </p>

<p>6 12 18 
Percent </p>

<p>0 
1 
2 
3 
4 
5 </p>

<p>Value Reported </p>

<p>Panel E: CRT4 </p>

<p>−12 −6 </p>

<p>0 </p>

<p>6 
12 18 </p>

<p>Percent </p>

<p>0 
1 
2 
3 
4 
5 </p>

<p>Value Reported </p>

<p>Panel F: CRT5 </p>

<p>Figure 15. Treatment Effect of CRT: Nonrollers. 
Notes: Reported is the treatment effect for each of the CRT among nonrollers. For each panel, each bar repre-
sents the share of subjects reporting that number in the respective CRT minus the share of subjects reporting 
that number in SRT. Because the pay-off for rolling a 6 is zero, we recode the outcome 6 as 0. </p>

<p>Table 3. Distribution of Gender Across Treatments </p>

<p>Treatment 
Male 
Female 
Obs </p>

<p>SRT 
49.8 
50.3 
201 
CRT (pooled) 
56.1 
43.9 
1258 
CRT Sub-groups 
CRT:0 
52.5 
47.5 
223 
CRT:1 
59.4 
40.6 
207 
CRT:2 
63.2 
36.8 
201 
CRT:3 
50.8 
49.3 
199 
CRT:4 
53.7 
46.3 
216 
CRT:5 
57.6 
42.5 
212 
Total 
55.24 
44.76 
1459 </p>

<p>SRT is self-report treatment, and CRT is confirmation-report treatment. </p>

<p>Effect of Confirmation-Reports on Dishonesty </p>

<p>
females (p value 5 0.16). The nonuniformity of the distributions is confirmed by a binomial two-
sided test that the share of subjects reporting each number is 16.67%. </p>

<p>18 </p>

<p>These two results confirm the presence of lying among both males and females. Further evi-
dence of greater dishonesty among males is presented in Figure 17, which shows that females are 
more likely to report smaller numbers compared to males. 
Gender differences are also obvious in each subgroup of the CRT data. Both females and 
males lie regardless of the prefilled number on the confirmation report (see Figures 18 and 19). 
Additionally, Figure 20, which reports-for each CRT subgroup-the difference between the </p>

<p>Table 4. Share of Die Rollers </p>

<p>Nonrollers 
Rollers </p>

<p>Die 
Percent 
Obs 
Percent 
Obs 
Total </p>

<p>SRT 
36.5 
74.0 
63.6 
129.0 
203 
CRT (Pooled) 
35.22 
448 
64.78 
824 
1272 
CRT Sub-groups 
CRT:0 
36.89 
83 
63.11 
142 
225 
CRT:1 
29.81 
62 
70.19 
146 
208 
CRT:2 
41.18 
84 
58.82 
120 
204 
CRT:3 
33.66 
68 
66.34 
134 
202 
CRT:4 
36.53 
80 
63.47 
139 
219 
CRT:5 
33.18 
71 
66.82 
143 
214 </p>

<p>SRT is self-report treatment, and CRT is confirmation-report treatment. Rollers is a binary variable indicating that 
the subject clicked on the die-roll link. Nonrollers did not click on the die-roll link. </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>Percent </p>

<p>0 
1 
2 
3 
4 
5 
Value Reported </p>

<p>Panel A: SRT Females </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>0 
1 
2 
3 
4 
5 
Value Reported </p>

<p>Panel B: SRT Males </p>

<p>Figure 16. SRT Gender Effect. 
Notes: Reported is the distribution of die outcomes for the self-report (SRT) and CRT by gender. Because the 
pay-off for rolling a 6 is zero, we recode the outcome 6 as 0. The horizontal line indicates 16.67%. [Color fig-
ure can be viewed at wileyonlinelibrary.com] </p>

<p>18 We find that females are more likely to report the theoretically expected share of each number compared to males, </p>

<p>except for the number 3. </p>

<p> 
Denvil Duncan and Danyang Li </p>

<p>−12 </p>

<p>−9 </p>

<p>−6 </p>

<p>−3 </p>

<p>0 </p>

<p>3 </p>

<p>6 </p>

<p>Percent </p>

<p>0 
1 
2 
3 
4 
5 </p>

<p>Value Reported </p>

<p>SRT </p>

<p>Figure 17. Females versus Males in SRT. 
Notes: Reported is the effect of gender on reporting behavior for self-report and confirmation-report, 
respectively. For each panel, each bar represents the share of females reporting that number minus 
the share of males reporting that number. Because the pay-off for rolling a 6 is zero, we recode the 
outcome 6 as 0. </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Percent </p>

<p>Panel A: CRT0 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Percent </p>

<p>Panel B: CRT1 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Percent </p>

<p>Panel C: CRT2 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Percent </p>

<p>0 1 2 3 4 5 
Value Reported </p>

<p>Panel D: CRT3 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Percent </p>

<p>0 1 2 3 4 5 
Value Reported </p>

<p>Panel E: CRT4 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Percent </p>

<p>0 1 2 3 4 5 
Value Reported </p>

<p>Panel F: CRT5 </p>

<p>Figure 18. CRT Female Conditional on Prepopulated Number. 
Notes: Reported is the distribution of die outcomes for the CRT for females. Because the pay-off for rolling a 
6 is zero, we recode the outcome 6 as 0. The horizontal line indicates 16.67%. [Color figure can be viewed at 
wileyonlinelibrary.com] </p>

<p>Effect of Confirmation-Reports on Dishonesty </p>

<p>
share of females reporting a given number and the share of males reporting that same number, con-
firms our earlier finding that females are more likely to report smaller numbers compared to males. 
Over all, then, our results suggest that relative to males, females are either more likely to 
report honestly and/or more likely to tell smaller lies. </p>

<p>Result 9. The Treatment Effect of CRT Varies Across Gender. In particular, </p>

<p>CRT has a larger treatment effect on share of maximal liars among females than among males. 
CRT reduces the share of partial liars among males, but increase the share of partial 
liars among females. </p>

<p>CRT affects partial and maximal lying differently across gender. On the one hand, CRT 
increases partial lying and reduces maximal lying among females. On the other hand, CRT 
reduces partial lying and has no effect on maximal lying among males. Additionally, while 
CRT increases the share of reported zeroes among males and female, there is a much larger 
response among males. </p>

<p>4. Discussion </p>

<p>The empirical results described in results section show evidence of both honest and dishonest 
subjects. We also find that not all subjects lie maximally. Importantly, we estimate that the CRT </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Percent </p>

<p>Panel A: CRT0 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Percent </p>

<p>Panel B: CRT1 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Percent </p>

<p>Panel C: CRT2 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Percent </p>

<p>0 1 2 3 4 5 
Value Reported </p>

<p>Panel D: CRT3 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Percent </p>

<p>0 1 2 3 4 5 
Value Reported </p>

<p>Panel E: CRT4 </p>

<p>0 </p>

<p>10 </p>

<p>20 </p>

<p>30 </p>

<p>40 </p>

<p>Percent </p>

<p>0 1 2 3 4 5 
Value Reported </p>

<p>Panel F: CRT5 </p>

<p>Figure 19. CRT Male Conditional on Prepopulated Number. 
Notes: Reported is the distribution of die outcomes for the CRT for males. Because the pay-off for rolling a 6 
is zero, we recode the outcome 6 as 0. The horizontal line indicates 16.67%. [Color figure can be viewed at 
wileyonlinelibrary.com] </p>

<p> 
Denvil Duncan and Danyang Li </p>

<p>has an economically meaningful effect on the share of subjects who report each number, but the 
magnitude depends greatly on the prefilled number in the CRT. This section places our findings to 
the context of the existing literature and offers possible explanations for the observed treatment 
effects. </p>

<p>Relation to Literature </p>

<p>Our baseline findings reported in self-report treatment results section are consistent with the 
existing literature (Suri et al. 2011; Fischbacher and F€ ollmi-Heusi 2013; Jiang 2013; Abeler, 
Becker, and Falk 2014; Ruffle and Tobol 2014; Hao and Houser 2017). A particularly useful point 
of comparison is Fischbacher and F€ ollmi-Heusi (2013) whose baseline-experimental design is sim-
ilar to our SRT treatment. They estimate that their sample includes 39% unconditionally honest 
subjects, 22% maximal liars, and a nontrivial amount of partial lying. Our results are largely com-
parable to theirs, which is reassuring on two levels. First, though use of the mTurk subject pool 
has grown significantly in recent years, there still remains some skepticism. Therefore, the fact that 
Fischbacher and F€ ollmi-Heusi (2013) baseline results are replicated in the mTurk sample ought to 
increase confidence in our results. Second, mTurkers generally complete HITs for very low wages 
and as such the stakes in our experiment are low relative to the existing literature. For example, 
ignoring exchange rate differences, the stakes in Fischbacher and F€ ollmi-Heusi (2013) are 10 times 
as high as in our experiment. Still, our baseline results are very similar to theirs, which suggests </p>

<p>−12 
−8 −4 0 </p>

<p>4 
8 12 </p>

<p>Percent </p>

<p>0 
1 
2 
3 
4 
5 </p>

<p>Panel A: CRT0 </p>

<p>−12 
−8 −4 0 </p>

<p>4 
8 12 </p>

<p>0 
1 
2 
3 
4 
5 </p>

<p>Panel B: CRT1 </p>

<p>−12 −8 −4 0 </p>

<p>4 
8 12 </p>

<p>0 
1 
2 
3 
4 
5 </p>

<p>Panel C: CRT2 </p>

<p>−12 −8 −4 0 4 </p>

<p>8 12 </p>

<p>Percent </p>

<p>0 
1 
2 
3 
4 
5 </p>

<p>Value Reported </p>

<p>Panel D: CRT3 </p>

<p>−12 −8 −4 0 </p>

<p>4 8 12 </p>

<p>0 
1 
2 
3 
4 
5 </p>

<p>Value Reported </p>

<p>Panel E: CRT4 </p>

<p>−12 −8 −4 0 </p>

<p>4 
8 12 </p>

<p>0 
1 
2 
3 
4 
5 </p>

<p>Value Reported </p>

<p>Panel F: CRT5 </p>

<p>Figure 20. CRT Female versus Male Conditional on Prepopulated Number. 
Notes: Reported is the effect gender on reporting behavior for the confirmation-report treatments. For each 
panel, each bar represents the share of females reporting that number minus the share of males reporting that 
number. Because the pay-off for rolling a 6 is zero, we recode the outcome 6 as 0. </p>

<p>Effect of Confirmation-Reports on Dishonesty </p>

<p>
that the size of the stake is not that important in matters of dishonesty (at least not in the context 
that we explore). </p>

<p>19 </p>

<p>We also note that our treatment effects are consistent with Fonseca and Grimshaw (2017) 
who find that correctly prepopulated tax returns have a small positive effect on compliance relative 
to a blank return. Like us, they also find that prepopulating a return with too low values for 
income (similar to overstating the die outcome in our case) increases dishonesty. </p>

<p>Channels </p>

<p>Again, the novelty of our experiment is that we test whether confirmation-reports cause sub-
jects to become more or less honest in an environment where there are no extrinsic lying costs. Our 
results suggest that, overall, confirmation reports increase honesty. However, we also observe that 
the effect of CRT depends on the prefilled information and whether or not the subject clicked our 
roll-die link. We argue that this heterogenous effect is due to intrinsic costs broadly defined to 
include moral lying-costs and decision-making costs related to the mental burden of whether and 
how much to lie. </p>

<p>Moral Lying-Costs </p>

<p>Dishonesty is morally costly for individuals because they must violate their moral standards 
in order to engage in a dishonest act (Bandura 1990, 1996; Aquino and Reed II 2002). We argue 
that confirmation-reports affect the moral cost of lying by changing the salience of subjects own 
moral standards. For example, a subject who faces an accurate confirmation-report has to engage 
in two distinct dishonest acts if she wishes to lie; she must reject the true statement, then report a 
false statement. These two decisions have a greater effect in activating her moral standards relative 
to a self-report, and thus increases the moral costs of lying. On the other hand, CRT reduces the 
moral-lying costs of subjects who are asked to confirm an advantageous false statement because 
they can shift the blame of lying to the person who prepared the confirmation report without nec-
essarily activating her own moral standards. For example, Erat (2013) finds that people are more 
likely to lie if the burden of lying can be shifted to a delegate. We argue that these opposing effects 
on the moral cost of lying is a possible explanation for our results. 
To illustrate, let us take to the two extreme pay-off numbers of zero (lowest pay-off) and five 
(highest pay-off). CRT subjects who roll a zero and are asked to confirm a zero face higher lying 
costs relative to subjects who rolled a zero in SRT. We would therefore expect an increase in the 
share of reported zeroes in CRT relative to SRT, and this is exactly what we find. Importantly, 
because there is no incentive to report a zero unless it is the truth, we can interpret the increase in 
the share of reported zeroes as an increase in honesty. Similarly, CRT subjects who rolled a number 
less than five, but are asked to confirm rolling a five, face lower lying costs relative to SRT subjects 
who rolled a number less than five. Therefore, we would expect an increase in the share of reported 
fives in CRT5 relative to SRT. Again, this is what we find. Because subjects do not have an incen-
tive to report a number lower than their actual roll, we argue that the treatment effect for reported 
fives in CRT5 reflects an increase in dishonesty. </p>

<p>19 Fischbacher and F€ ollmi-Heusi (2013) came to a similar conclusion after tripling the stakes in their experiment and </p>

<p>finding that the higher stakes did not affect their results. </p>

<p> 
Denvil Duncan and Danyang Li </p>

<p>We can use the same logic to explain the responses for the intermediate numbers one to four. 
Consider, for example, the number three. We can classify subjects who are asked to confirm the 
number three into four bins: (i) those who roll a number lower than three, and would self-report a 
number lower than three, (ii) those who roll a number lower than three, but would self-report a 
number greater than or equal to three, (iii) those who roll the number three, and (iv) those who roll 
a number greater than three. Prefilling the confirmation report with the number three reduces the 
lying cost for subjects in the first two bins and increases the lying cost for those in the third bin. 
The impact on lying costs for those who roll a four is unclear. This suggests that the share of 
reported threes should increase, which is what we observe, and that this effect is driven by the 
response of subjects in the first three bins. The greater share of threes reflects an increase in lying 
among subjects in the first bin since they experience lower lying costs. It also possibly includes a 
reduction in the magnitude of the lie told by subjects in the second bin. In other words, subjects 
who roll a one and would have self-reported a five now report a three; they still lie, but the magni-
tude of the lie is smaller. Finally, the effect of prefilling the report with the number three includes 
increased honesty among subjects who actually roll a three because these subjects experience 
higher lying costs. </p>

<p>Decision-Making Costs </p>

<p>Another possible explanation for our findings is that subjects simply accept the number that 
is prepopulated because it is the default setting of the confirmation report. Economists have 
highlighted in numerous areas, including health care plans (Samuelson and Zeckhauser 1988), 
automobile insurance (Johnson et al. 1993), retirement saving plans (Madrian and Shea 2001), 
and organ donor registration (Johnson and Goldstein 2003; Li, Hawley, and Schnier 2013), that 
people often choose the default option they are assigned in order to reduce decision-making costs. 
Because it is less mentally burdensome to accept the default number shown on the confirmation 
report than to decide on a number to report, we would expect subjects who roll a number x y to 
be more likely to confirm rolling y than self-reporting y. We argue that this channel is especially rel-
evant among nonrollers. To the extent that nonrollers did not in fact roll a die, they need to decide 
which number to self-report in order to maximize their pay-off while maintaining a semblance of 
honesty. 
20 The default option presented in the confirmation-report simplifies this decision-</p>

<p>making calculus by allowing the subject to simply accept the prepopulated number. Unlike rollers, 
nonrollers do not have an actual die outcome (x) with which to compare the prepopulated 
number (y). Therefore, it is not surprising that, relative to rollers, nonrollers are more likely to 
accept y, thus leading to much larger treatment effects among nonrollers. </p>

<p>Shame </p>

<p>It is also possible that our result is driven by shame aversion induced by a change in subjects 
beliefs about the researchers information set. The argument goes as follows. Upon seeing a pre-
filled number, subjects update their beliefs of the accuracy of the researchers information set 
regarding the actual die outcome. Subjects who see a prefilled number equal to their actual die roll </p>

<p>20 Recall that we can only tell if the subject clicked on the die-roll link. We cannot tell if they roll their own personal die </p>

<p>or a virtual die on some other website. </p>

<p>Effect of Confirmation-Reports on Dishonesty </p>

<p>
now believe that the researcher knows the actual outcome, and will therefore report accurately. 
Subjects who see a prefilled number that is different from their actual die roll will confirm their 
prior belief that the researchers do not know the actual outcome, and are therefore more likely to 
confirm a favorable false statement. Note that in both cases the effect of the updated beliefs on 
lying works through its effect on intrinsic costs only. 
21 In other words, subjects wish to lie, but </p>

<p>would like to appear honest in order to avoid the shame of being known as a liar (Greenberg, 
Smeets, and Zhrakhovska 2015; Hao and Houser 2017). As a result, subjects who believe the 
researchers information set is correct are more likely to confirm an accurately prefilled confirma-
tion report while those who believe the researchers information set is inaccurate are more likely to 
confirm a favorably inaccurate confirmation report. 
We argue that this mechanism is an unlikely reason for our results given the design of the 
experiment. First, we make it explicitly clear to subjects that our website is not connected to ran-
dom.org in anyway, and that we cannot observe their die rolls. Second, subjects know that we only 
observe their mTurk ID and therefore have no way of knowing any of them personally. Third, the 
actual reported outcomes appear to be inconsistent with this explanation. For example, if prefill-
ing the form with say three, fours and fives lead subjects who roll a zero to believe we do not know 
their actual outcomes, then we would expect to observe a significant drop in the share of reported 
zeroes in treatments CRT3, CRT4, and CRT5 relative to SRT and relative to CRT0, CRT1 and 
CRT2. However, the share of reported zeroes is basically constant across all of these treatments. 
Finally, we also rule out this alternate explanation based on the fact that subjects who did 
not click on the "die roll" link embedded in our website responded similarly to those who did click 
on the link. Subjects belief of the researchers information set should be unaffected by the prefilled 
number for subjects who did not click on the "die roll" link. This is because these subjects either 
rolled a physical die, rolled a virtual die on some other website, bypassed our weblink in order to 
roll the die on random.org, or did not roll a die at all. In either case, these subjects should be reas-
sured that the researchers do not know the actual outcome of the die roll, and so, their beliefs of 
the researchers information set should be independent of the prefilled number. This suggests that 
the treatment effect of CRT0 on the share of subjects who confirm rolling zero should be lower 
among nonrollers relative to rollers. Similarly, the treatment effect of CRT5 on the share of sub-
jects who confirm rolling five should be higher among nonrollers relative to rollers. However, this 
is not what we observe. In fact, the treatment effect of CRT0 on confirmed zeroes is much higher 
among nonrollers, while the treatment effect of CRT5 on confirmed fives is lower among nonroll-
ers. This suggests that a change in beliefs about the probability of being observed is not the driving 
factor. 
Of course we cannot rule out the possibility that different subjects are influenced by different 
factors. For example, it is possible that nonrollers are influenced by decision-making costs while 
rollers are mostly influenced by moral costs with some residual social (shame) costs. </p>

<p>Policy Implications </p>

<p>Our findings are important for policy areas where information requests can reasonably take 
the form of either a self-report or a confirmation-report; for example, tax administration. Several </p>

<p>21 Recall that there is no audit and no penalty for lying. Therefore, even if a subject believes that the researchers knows </p>

<p>her actual die roll, it is still profitable to lie since there are no extrinsic costs associated with lying. </p>

<p> 
Denvil Duncan and Danyang Li </p>

<p>countries have adopted prepopulated tax forms, and others are considering adoption. It is gener-
ally argued that a prepopulated tax system lowers compliance costs and thus increases tax compli-
ance. However, there is very little empirical evidence on the compliance effects of prepopulated tax 
systems; Fonseca and Grimshaw (2017) provide experimental evidence for the UK and Kotakorpi 
and Laamanen (2015) evaluate the effect of Finlands switch to prepopulated returns. 
While our experiment is not framed as a study of tax compliance, the results do provide some 
insights into the possible effects of prepopulation since prepopulated tax systems rely on confirma-
tion-reports. 
22 For example, we show that the effect of confirmation-reports on honesty (and </p>

<p>hence tax compliance) depends greatly on the accuracy of the prepopulated information. Consider 
taxpayers who have both third-party reported (e.g., wage income subject to W2 reporting in the 
US) and self-employment income (e.g., income reported on form 1099 in the US). These taxpayers 
may be of one of three types. The first type of taxpayer reports some of her W2 income and none 
of her self-employment income. Our results suggest that switching to prepopulated tax returns 
under these conditions would increase compliance for two reasons: (i) people are more likely to 
confirm prefilled information that is favorably inaccurate, and (ii) W2 income is easily verifiable. </p>

<p>23 </p>

<p>Of course, compliance with third-party income is already very high; for example, estimates put the 
compliance rate for W2 income at 99% in the United States (Slemrod 2007). Therefore, the posi-
tive effect on compliance from the introduction of prepopulated tax returns among this group of 
taxpayers is likely to be very small. 
The second type of taxpayer fully reports W2 income and none of the self-employment 
income. The compliance rate among these taxpayers is likely to be unaffected by a switch to pre-
filled tax returns because the prefilled return reflects what the taxpayer would have self-reported. 
Finally, there are taxpayers who report all of their W2 income and some or all of their self-
employment income. Our results suggest that switching to prepopulated tax forms that are based 
solely on third-party reported information would increase noncompliance among these taxpayers. 
This follows from the fact that people are more likely to confirm favorably inaccurate information. 
Notice that in this case, the prepopulated information on total income is both inaccurate and 
lower than what the taxpayer would have self-reported. Another implication of our findings is that 
policymakers who wish to reduce noncompliance among these two types of taxpayers could prefill 
self-employment income on tax forms with high income values. 
24 However, as a matter of practical </p>

<p>policy making, it might be unethical for the government to knowingly provide taxpayers with inac-
curate prefilled tax returns. Therefore, we recommend that policymakers who wish to implement 
prepopulated tax forms limit them to taxpayers whose income is easily verifiable. 
Overall, the net effect of switching to prepopulated tax forms on compliance depends on the 
distribution of third-party and nonthird-party reported income. We would expect a small positive 
effect on compliance if all income is subject to third-party reporting. This is because compliance 
with third-party income is already very high. However, the net effect depends on the existing level 
of compliance if there is at least some income not subject to third-party reporting. </p>

<p>22 Recall that our experiment does not include any extrinsic costs. Therefore, our findings/policy implications are based </p>

<p>solely on the direct effect of the form, and excludes any indirect effects that might occur through perceived (or actual) 
changes in extrinsic costs. 
23 The taxpayer is unlikely to reduce the prefilled W2 income because she knows that the tax administrator has third-</p>

<p>party information on her W2 income. This effect is also likely to hold for taxpayers who only have third-party 
reported income. 
24 The determination of self-employment status as well as realistic "high" values for self-employment income could be </p>

<p>determined from tax returns of previous years. </p>

<p>Effect of Confirmation-Reports on Dishonesty </p>

<p>
Of course, the importance of accuracy is not a new finding. 
25 What is novel in our setting is </p>

<p>that we show that this compliance effect exists even in the absence of extrinsic evasion costs; that 
is, costs related to being audited and fined. We argue that this effect is driven by changes in the 
intrinsic costs of lying that are induced by the confirmation-report; while accurate information 
increases intrinsic lying costs, inaccurate information reduces intrinsic lying costs. 
Another application closely related to our field experiment context is the reporting of annual 
vehicle miles traveled (VMT) for auto-insurance policies. Auto insurers often ask policy holders to 
self-report their annual VMT and use this information in pricing insurance policies. Those who 
drive more tend to have a higher accident risk and are therefore charged higher insurance premi-
ums. Therefore, policyholders have an incentive to underreport their VMT. 
26 Insurance companies </p>

<p>can rely on several techniques to obtain accurate mileage information. 
27 One suggested technique </p>

<p>uses two steps. First, known information about customers is used to predict their annual mileage; 
for example, gender, age, education, employment commute times, vehicle type, and vehicle age. 
Second, customers are asked to confirm that the predicted mileage is correct using confirmation 
reports. The effect of this approach on underreporting depends on the accuracy of the predicted 
mileage. Assuming that the predicted mileage is fairly accurate, our findings suggest that this 
approach could significantly reduce the under-reporting problem. 
A similar strategy might also prove useful if road mileage user-fees become widely adopted. 
Ideally, a road mileage user-fee would be implemented with the aid of advanced technology that 
accurately measures vehicle mileage. However, due to costs and privacy concerns, there has been 
some resistance to mileage user-fees and the use of advanced technology in particular (Duncan 
et al. 2014). Because of these costs and privacy concerns, administration with odometer readings 
is generally included as an optional way of collecting mileage information. While odometer read-
ing largely solves the privacy and cost problems, it raises concerns about evasion. Our results sug-
gest that obtaining a fairly accurate estimate of vehicle miles traveled coupled with a confirmation 
report is likely to reduce noncompliance. This could serve to reduce the number of required audits 
and hence the cost of administration. </p>

<p>5. Conclusion </p>

<p>We implement a field experiment to study the effect of confirmation reports on dishonesty. 
Subjects are recruited from Amazons Mechanical Turk labor pool. Each subject is asked to roll a 
virtual die and report the outcome of the die roll either by completing a self-report or confirmation 
report. We find strong evidence of lying in both treatments. We also find that the effect of confir-
mation report is heterogenous across prefilled number, gender, and roller status. Overall, we find 
that people are more likely to confirm the truth than to self-report the truth, and more likely to 
confirm a lie than to tell a lie. We attribute our findings to intrinsic costs which are influenced 
through the impact of confirmation reports on moral-lying costs and decision-making costs. </p>

<p>25 Almost all countries with a prepopulated tax system either limit to their system to (or began with) taxpayers with only </p>

<p>wage income that is easily monitored for accuracy. 
26 According to a 2008 report by Quality Planning company, the car insurance industry missed out on $15.9 billion in </p>

<p>revenues of which more than $3 billion is due to underreported vehicle mileage. 
27 These include asking the customer, asking the agent, historical odometer readings, mileage models, and telematics </p>

<p>using an after-market device, smartphone OEM-based or smartphone odometer app (Cantwell 2015). </p>

<p> 
Denvil Duncan and Danyang Li </p>



<p>Effect of Confirmation-Reports on Dishonesty </p>



<p>
 
Denvil Duncan and Danyang Li </p>

</text></tei>